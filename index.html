<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>James @ james-shao.me</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="javascripts/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>James Shao</h1>
        <p><a href="mailto:jshao100@gmail.com">jshao100@gmail.com</a> || <a href="mailto:shao57@purdue.edu">shao57@purdue.edu</a></p>
        <p>+1 917.463.8818 
		<p class="view"><a href="https://github.com/jshao100/GitHub-Webpage">View the Project on GitHub <small>jshao100/GitHub-Webpage</small></a></p>
        <ul>
          <li id="hover"><a href="JamesShao_Resume.pdf">View<strong>Resume</strong></a></li>
          <li id="hover"><a href="https://github.com/jshao100/">View<strong>GitHub</strong></a></li>
		  <li id="hover"><a href="https://www.linkedin.com/in/JamesShao">View<strong>LinkedIn</strong></a></li>
        </ul>
      </header>
      <section>
        <h2>
<a name="about-me" class="anchor" href="#about-me"><span class="octicon octicon-link"></span></a>About Me.</h2>

<p>My name is James and I am currently a freshman enrolled at Purdue University studying Computer Science. I have 4 years of CS under my belt, albeit I only started seriously studying it my Junior year of High School. </br></br>

In my free time, I enjoy taking naps, browsing Reddit, learning various Computer Science topics (such as swift), working on projects, and, last but not least, playing League. I am an avid League of Legends player and fan (Go TSM!), so feel free to add me in game: <i>Crisios</i>. </br></br>

If you're looking for a summary of my experience, that's not really what this site is for, but feel free to browse the links above. If you want to read about my ramblings and projects, then by all means, continue scrolling!</p>
	
<h2>
<a name="current-projects" class="anchor" href="#current-projects"><span class="octicon octicon-link"></span></a>Current Projects.</h2>

<p> I have a few interesting projects that I picked up due to various interesting aspects that I found appealing. This section will talk about my current projects, if you want to see what I have done in the past, scroll to the bottom or click <i><a href="#past-projects">here</a></i>. If you continue reading, you'll find chunks of code and my thought process behind each project. </br></br>

I have provided some quicklinks for convenience:
<ul class="list">
<li style="display:block;float:left;"><a href="#lolsearch">LoL Search Engine</a></li></br>
<li style="display:block;float:left;"><a href="#lolstat">LoL Log Reader</a></li></br>
<li style="display:block;float:left;"><a href="#website">Website</a></li></br>
</ul>

<strong><i>NOTE: This section will always be a work in progress. I will continuously be updating projects as I add more and more features.</strong></i></p>

<!-- PROJECTS SECTION -->
<h6><a name="lolsearch" class="anchor" href="#lolsearch"><span class="octicon octicon-link"></span></a>League of Legends Search Engine</h6><p><i><a href="http://www.lolsearch.net">http://www.lolsearch.net</a></p></i>

<p>If you play League of Legends, then you most likely know about lolnexus, lolking, op.gg, or some other player and game search platform that provides relevant data. For months, I had used sites like that before I sat down and wondered how exactly they got their data. Did they have dozens of accounts that were scripted to look up players and spectate games? </br></br> 

No &mdash; instead, I found that most of these sites were reliant on Riot Games API to query searches and return the information summoners were searching for. OK, problem solved - back to using those searches. </br></br>

But wait! Wouldn't it be interesting if I could create something like those websites? Not for exposure or marketing, but just to prove to myself that I could create something tangible with my Computer Science skills. And so it beganOK, problem solved - back to using those searches. But wait! Wouldn't it be interesting if I could create something like those websites? Not for exposure or marketing, but just to prove to myself that I could create something tangible with my Computer Science skills. And so it began. </br></br>

Alright, what do I need to do? HTML, CSS, API requests, the list went on. It was a daunting task to take on, especially as a side project, but I found that I enjoyed working. I could work on the site, perfecting the css or php, for hours on end. Now, let's get to the interesting part - what I learned. </br></br>
When I first finished a prototype of the project, I ran into two issues. The first was not having enough api requests to query enough times to fill the table. I was limited in the number of api requests I could do over the course of 10 seconds so if more than 1 or 2 people used the site, they would get get blank areas on information in the table, such as missing division info or no name and champion, etc...</br></br> 
My solution at first was simple, as a group of friends for their developer key so I could have each query run off a different key. This would provide me with up to 5x more requests. However, I realized that this was like covering a leak in a ship with my finger, I needed to find out how to optimize my api usage.</br></br>

The second issue was that the website was too slow. By the time it finished one search, other websites had already finished loading the results. I examined my code carefully, unsure where the issue of speed came from. Was it because the website was hosted on my raspberry pi? Was it because processing a massive json array took time? Was it because I was being extremely unefficient somewhere?</br></br>

Eventually, I found out that I was not using my curls effectively and instead should reuse the same curl handler without running curl_close. This would speed up the website a little bit. Finally, I could use curl_multi_init to run the processes in parallel and therefore have multiple requests run at the same time.</br></br>

Let's take this snippet of code from the website as an example.

<pre><code>function kda_stats($region,$list){
	$id_list=array();
	$champion_list=array();
    $nodes=array();
    foreach($list as $value){
    	list($id,$champion)=split(',',$value);
        $id_list[]=$id;
        $champion_list[]=$champion;
        $nodes[]=...;
    }
</code></pre>

In this function, I wanted to get the kda of everyone in the game. Initially, I searched each summoner individually and then checked his kda for the champion he was playing. I ended up redoing the code and running it through a parallel curl. In this section, I was loading all the url's of the players into the nodes array. I was given the region and a list of summoner ids. Through this, I could use a for loop as an assembly line to produce all the urls.</br></br>
<pre><code>    $node_count = count($nodes);
	
    $curl_arr = array();
    $master = curl_multi_init();
</code></pre>

I then initialize the multi_init for curl.</br></br>

<pre><code>    for($i = 0; $i < $node_count; $i++) {
        $url =$nodes[$i];
        $curl_arr[$i] = curl_init($url);
        curl_setopt($curl_arr[$i], CURLOPT_RETURNTRANSFER, true);
        curl_multi_add_handle($master, $curl_arr[$i]);
    }

    do {
        curl_multi_exec($master,$running);
    } while($running > 0);

...
</code></pre>

Finally, I load each url into the array and then run it through the parallel curl before separating the results. I take all the urls that I had created prior and add them to an array after running them through curl_init. Then, they are run in parallel until the JSONs are all returned. I'm not showing the rest of the function, but it ends up calculating and returning the kda and number of games played on each summoner's champion.</br></br>

On a side note, a fun aspect of this project was making the buttons you see on the front page through css. Initially, I was using a drop down menu where you could select the region you wanted to search, but I ended up deciding that radio buttons might look nicer. However, the radio buttons without css looked miserable and I ended up messing with the css quite a bit. </br></br>

<pre><code>&lt;form method="get" id="search" style="margin:0;padding:0"&gt;
    &lt;span&gt;&lt;input type="text" class="search-rounded" name="name" id="name" placeholder="..."&gt;&lt;/span&gt;
    &lt;div class="button centered" onclick="document.getElementById('search').submit()"&gt;Search a Summoner&lt;/div&gt;
    &lt;div&gt;
        &lt;br&gt;
        &lt;input type="radio" id="radio1" name="region" value="na" checked/&gt;
            &lt;label for="radio1"&gt;NA&lt;/label&gt;
        &lt;input type="radio" id="radio2" name="region"value="euw"/&gt;
            &lt;label for="radio2"&gt;EUW&lt;/label&gt;
        &lt;input type="radio" id="radio3" name="region" value="eune"/&gt;
            &lt;label for="radio3"&gt;EUNE&lt;/label&gt;

etc... rest of the selections				  
</code></pre>

Pretty self explanatory, the magic happens in the CSS file where I had two main css blocks.</br></br>

<pre><code>input[type="radio"] + label { ... }
input[type="radio"]:checked + label { ... }
</code></pre>

I didn't put the exact css in because of the length, however, I will go over what I did. First, I changed the background to a very faint gradient in order to make the buttons stand out from each other. Furthermore, I changed the cursor to a pointer when it moused over the buttons, further making them stand out. By adjusting the gradient from the edge to be very slight, it gave the buttons depth and therefore made them pop. </br></br>

Then I changed the appearance of the radio button when checked. I gave the button a shadow inwards so that it appeared to be embedded and made the color darker. By doing this, I made it appear to have sunk into the page and therefore have been "selected."</br></br>

To Be Continued...
</p>

<!-- BREAK -->
</br><hr></br>


<h6><a name="lolstat" class="anchor" href="anchor"><span class="octicon octicon-link"></span></a>League of Legends Log Parser</h6><p><i><a href="https://github.com/jshao100/lolstat">Github</a> &mdash; reads log files and prints miscellaneous information</p></i>
<p>One of my more recent projects, I was digging through my old python files when I stumbled upon this code. I picked it up nearly a year ago from <a href="http://www.lolparse.com">lolparse</a> before it was taken down. Since then, it has sat in my python folder, untouched, until now. If you want to tae a look at the complete code, click the title link for the github repository. Otherwise, I'll do a walkthrough of the code in logical order.</br></br>

While there are now sites like <a href="http://www.1lann.github.io/lolreader">lolreader</a>, I was intruigued and decided that I would figure out how the log files were read and processed. My main goal for this project was to understand how the code worked and possibly modify it for my own means. I ended up rewriting a bit of the code for various reasons, but mainly because Riot Games changed how the logs were recorded sometime last year. As seen in examples below, code that worked a year ago needed to be redone. Let's start in the main.</br>

<pre><code>#main
if __name__ == "__main__":
    run_report("Applications/League of Legends.app/Contents/LoL/Logs/Game - R3d Logs")
    #windows os users should redirect to the appropriate Logs folder
</code></pre>

If I recall correctly, this code was created before the official mac client was released. Because of this, there was only a windows operating system path available. What's interesting is the first line &mdash; when the python interpreter reads the source, it executes the code found. If python is running the module as the main program, <code>__name__</code> is set to have the value <code>"__main__"</code>. However, if the file is imported from a different module, <code>__name__</code> will be set to that module's name. By doing this, the program can be imported and the functions can be run by another module. Moving on, the imports are fairly self explanatory.</br></br>

<pre><code>from __future__ import print_function
import os, os.path
import sys
import re
</code></pre>

This is all very simple stuff. Importing from <code>__future__</code> sets a flag that tells the python interpreter how to behave. The <code>os</code>, <code>os.path</code>, and <code>sys</code> allow us to manipulate the Python environment and move through the file directories. Finally, <code>re</code> is used to parse out relevant keyword information through regex.</br></br>

The main then calls the function <code>def run_report(folder)</code> which takes the log folder as an import.</br></br>

<pre><code>def run_report(folder):
    if load_data():
        print('** Loaded existing data')
    else:
        print('** Parsing log files')
        read_files(folder)
        save_data()
        print('** Saved data for reuse')
        print()

    print_maps()
    summoner = print_summoners()
    summoner_stats(summoner)
</code></pre>

For now, let's skip the load_data() function and just assume that it does what it implies - checks whether there is a .txt file that was previously saved. The code then calls the <code>read_files(folder)</code> function which will return processed information from the log file's contents. This is then saved to a file in the directory through the save_data() function. Following the function <code>read_files(folder)</code>, we get to the heart of the code.</br></br>

<pre><code>def read_files(folder):
    files = os.listdir(folder)
    map_expr = re.compile(r'Initializing GameModeComponents for mode=(.+)')
    #OLDER VERSION - Stopped ~ 2013
    #map_expr = re.compile(r'Started Map (.+)')
    champ_expr = re.compile(r'Hero (.+) created for (.+)')
</code></pre>

Going through all the files, we use regular expressions via the re module we imported to parse out relavent information. I went through my friend's log files that date back to late 2012 and found that the parser could not read all of his files. In fact, approximately half of them returned no map information but complete champion information. By going through the files and comparing them, I found that at some point, Riot stopped recording information about the gamemode and map the same way. Previously, they used numbers which pointed to various gamemode and map ids, however, they recently have switched over to what you see now. </br></br>

From what I've found, the issue with this is that you cannot differentiate between certain game modes and types. Twisted Treeline and Summoner's Rift are both classified as CLASSIC, that's not even mentioning the fact that you can't tell whether the game is a normal or ranked. Furthermore, special gamemodes such as URF or One For All are not accounted for. However, the newest gamemode, Ascension, seems to have its own naming scheme which may lead to better data in the future.</br></br>

<pre><code>#log analysis
map_names = {
    "CLASSIC.": "Summoner's Rift / Twisted Treeline",
    "ARAM.": "Howling Abyss - ARAM / One for All",
    "ODIN.": "Crystal Scar - Dominion",
    "ASCENSION.": "Crystal Scar - Ascension",
    "TUTORIAL.": "Howling Abyss - Tutorial",
    "ONEFORALL.": "Summoner's Rift - One for All",
    "FIRSTBLOOD": "Howling Abyss - Snowdown Showdown"
}
</code></pre>

The parsed map expressions can later be run against a dictionary that prints the resulting gamemode and map type. Now, we want the user to know that the program is running so that they aren't staring at a blank screen while the log files are being parsed and interrupt the proccess with a refresh or stop command.</br></br>

<pre><code>    last_percent = 0
    for i, file in enumerate(files):
        percent = int(100 * i / len(files))
        if int(percent / 10) > int(last_percent / 10):
            last_percent = percent
            print('Completed %2d%%' % percent)
</code></pre>

The <code>for</code> loop is responsible for actually parsing the data by running each file through it at a time. In order to keep the user updated on the progress of the parsing, it finds the number of files in the folder, and then calculates how much it has completed based on the current file number.</br></br>

<pre><code>        with open(os.path.join(folder, file)) as f:
            lines = f.readlines()

        num = 0
        for line in lines:
            match = map_expr.search(line)
            if match:
                add_map(match.group(1))
                continue

            match = champ_expr.search(line)
            if match:
                add_champ(match.group(1), match.group(2))
                num += 1
                continue

            if 'GAMESTATE_GAMELOOP Begin' in line:
                break

    print('Finished reading %d log files' % len(files))
</code></pre>

We run through each file, taking each line as input and comparing it to the search expression we created above for gamemode and champion. If it matches, the string is added and the code continues. Once it reaches the end of the relevant log informatin, it breaks the loop and moves on in order to save time.</br></br>

Okay, so we've returned the relevant information, now what? Now we move onto printing the data in a readable format. If you ran the code for yourself from the git download (found <a href="https://github.com/jshao100/lolstat">here</a>). You would realize that the processed data is ugly and unreader, we need to format it for presentation. First comes <code>print_maps()</code>.</br></br>

<pre><code>def print_maps():
    print('== Top Maps ==')
    named_maps = {map_names.get(k,k): maps[k] for k in maps.keys()}
    #OLD VERSION - Stopped ~ 2013
    #named_maps = {map_names.get(k[:3],k): maps[k] for k in maps.keys()}
    pretty_print(named_maps)
    print()
</code></pre>

In older iterations of the logs and code, map data was stored by number, thus the commented out section that grabs the number and compares it against a dictionary. The current line compares the string with the new dictionary shown a few sections above and then returns the map's name and/or gamemode. For now, we'll ignore <code>pretty_print</code> and move on. We'll return to <code>pretty_print</code> at the end because it is called by all the functions before anything can print.</br></br>

We then run <code>print_summoners()</code> and then input the return information into <code>summoner_stats</code>.</br></br>

<pre><code>def print_summoners():
    print('== Top Summoners ==')
    played_with = {k: champs[k]['total'] for k in champs.keys()}
    r = pretty_print(played_with)
    print()
    return r
</code></pre>

Taking a look at the data file, we find that information is sorted by</br></br>

<pre><code>{map data}
{champ data}
</code></pre>

Expanding on champ data, we find that it stores data in this format:</br></br>

<pre><code>name
    total_games
    champions
        champ_name(skin):number_of_games
        champ_name(skin):number_of_games
        <i>continued until all champions listed</i>
name
name
<i>continued until all names listed</i>
</code></pre>

The function <code>print_summoners</code> prints the top summoners you have played with by running through all the names in the champ data and getting the value for 'total.' All of this is printed by <code>pretty_print</code>. Finally, the result is returned so that more information can be extracted in the <code>summoner_stats</code> function. </br></br>

<pre><code>def summoner_stats(name):
    print('== Stats for %s ==' % name)
    user = champs[name]
    print('Total games:', user['total'])

    print('Top 10 Champions')
    pretty_print(user['champs'])
    print()

    print('Top 10 Skins')
    pretty_print(user['skins'])
    print()
</code></pre>

The most played summoner name is then placed into this function. By navigating the champ data's structure, you can print the user's total number of games, champion, and skins of choice. This function is rather self-explanatory so it's time to move into <code>pretty_print</code>.</br></br>

<pre><code>def pretty_print(data, most=10):
    keys = sorted(data.keys(), key=data.get, reverse=True)
    maxlen = max(len(k) for k in keys[:most])
    fmt = '%-' + str(maxlen) + 's : %s'
    for k in keys[:most]:
        print(fmt % (k, data[k]))
    return keys[0]
</code></pre>

The function takes two inputs, the data and the number of items you want to print. The data is in the form of a dictionary, which means that it can then be sorted. Once it is sorted, you can produce a string that acts as a master template for the printing proccess. By using string format, the code just needs to run through the number of results the user wants (<code>most=10</code>), printing the information through the master template by inserting the relevant dictionary key/value entry. Finally, the first entry is returned, because logically, the top played would be the user himself.</br></br>

And that is essentially how the code works! I just cut it into readable chunks and presented it in the order of operation. My goal with this project is not to create something cool that I can publish, but instead to understand how the code works. If I were to write my own from scratch, it may not be as elegant or efficient. By understanding this code, I can take similar problems and solve them far more efficiently than before.</br>
</p>

</br><hr></br>

<h6><a name="website" class="anchor" href="website"><span class="octicon octicon-link"></span></a>Personal Website</h6><p><i>you are on it right now!</p></i>


<h2>
<a name="past-projects" class="anchor" href="#past-projects"><span class="octicon octicon-link"></span></a>Past Projects.</h2>

<p></p>

     </section>
    </div>
    <footer>
      <p>Project maintained by <a href="https://github.com/jshao100">jshao100</a></p>
      <p>Hosted on GitHub Pages.</p>
    </footer>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
  </body>
</html>
